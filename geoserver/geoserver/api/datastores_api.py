# coding: utf-8

"""
    GeoServer Workspace

    A workspace is a grouping of data stores. Similar to a namespace, it is used to group data that is related in some way.  # noqa: E501

    OpenAPI spec version: 1.0.0
    
    Generated by: https://github.com/swagger-api/swagger-codegen.git
"""

from __future__ import absolute_import

import re  # noqa: F401

# python 2 and python 3 compatibility library
import six

from geoserver.api_client import ApiClient


class DatastoresApi(object):
    """NOTE: This class is auto generated by the swagger code generator program.

    Do not edit the class manually.
    Ref: https://github.com/swagger-api/swagger-codegen
    """

    def __init__(self, api_client=None):
        if api_client is None:
            api_client = ApiClient()
        self.api_client = api_client

    def create_datastore(self, body, workspace_name, **kwargs):  # noqa: E501
        """Create a new data store  # noqa: E501

        Adds a new data store to the workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.create_datastore(body, workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param DataStoreInfoWrapper body: The data store body information to upload. The contents of the connection parameters will differ depending on the type of data store being added.
- GeoPackage


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"database","$":"file:///path/to/nyc.gpkg"},
            {"@key":"dbtype","$":"geopkg"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | database | Database | user | File | True | ` ` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | dbtype | Type | program | String | True | `geopkg` |
  | passwd | password used to login | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | user | user name to login as | user | String | False | ` ` |

- PostGIS


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"host","$":"localhost"},
            {"@key":"port","$":"5432"},
            {"@key":"database","$":"nyc"},
            {"@key":"user","$":"bob"},
            {"@key":"passwd","$":"postgres"},
            {"@key":"dbtype","$":"postgis"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | port | Port | user | Integer | True | `5432` |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |
  | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |
  | create database params | Extra specifications appeneded to the CREATE DATABASE command | advanced | String | False | `` |
  | dbtype | Type | program | String | True | `postgis` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | passwd | password used to login | user | String | False | ` ` |
  | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows to push more of the filter into the database, increasing performance.the postgis table. | advanced | Boolean | False | `False` |
  | host | Host | user | String | True | `localhost` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |
  | database | Database | user | String | False | ` ` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | preparedStatements | Use prepared statements | user | Boolean | False | `False` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | schema | Schema | user | String | False | `public` |
  | user | user name to login as | user | String | True | ` ` |

- Shapefile


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/nyc.shp"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |

- Directory of spatial files (shapefiles)


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/directory"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |


- Web Feature Service


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"GET_CAPABILITIES_URL","$":"http://localhost:8080/geoserver/wfs?request=GetCapabilities"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |
  | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |
  | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |
  | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |
  | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |
  | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |
  | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |
  | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |
  | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |
  | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |
  | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |
  | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |
  | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |
  | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |
  | Maximum features | Positive integer used as a hard limit for the amount of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |
  | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |
  | WFS Strategy | Override wfs stragegy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |
  | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |
  | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |
  | Outputformat | This allows the user to specify an outputFormat, different from the default one. | advanced | String | False | ` ` |
 (required)
        :param str workspace_name: The name of the worskpace containing the data stores. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.create_datastore_with_http_info(body, workspace_name, **kwargs)  # noqa: E501
        else:
            (data) = self.create_datastore_with_http_info(body, workspace_name, **kwargs)  # noqa: E501
            return data

    def create_datastore_with_http_info(self, body, workspace_name, **kwargs):  # noqa: E501
        """Create a new data store  # noqa: E501

        Adds a new data store to the workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.create_datastore_with_http_info(body, workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param DataStoreInfoWrapper body: The data store body information to upload. The contents of the connection parameters will differ depending on the type of data store being added.
- GeoPackage


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"database","$":"file:///path/to/nyc.gpkg"},
            {"@key":"dbtype","$":"geopkg"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | database | Database | user | File | True | ` ` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | dbtype | Type | program | String | True | `geopkg` |
  | passwd | password used to login | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | user | user name to login as | user | String | False | ` ` |

- PostGIS


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"host","$":"localhost"},
            {"@key":"port","$":"5432"},
            {"@key":"database","$":"nyc"},
            {"@key":"user","$":"bob"},
            {"@key":"passwd","$":"postgres"},
            {"@key":"dbtype","$":"postgis"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | port | Port | user | Integer | True | `5432` |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |
  | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |
  | create database params | Extra specifications appeneded to the CREATE DATABASE command | advanced | String | False | `` |
  | dbtype | Type | program | String | True | `postgis` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | passwd | password used to login | user | String | False | ` ` |
  | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows to push more of the filter into the database, increasing performance.the postgis table. | advanced | Boolean | False | `False` |
  | host | Host | user | String | True | `localhost` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |
  | database | Database | user | String | False | ` ` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | preparedStatements | Use prepared statements | user | Boolean | False | `False` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | schema | Schema | user | String | False | `public` |
  | user | user name to login as | user | String | True | ` ` |

- Shapefile


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/nyc.shp"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |

- Directory of spatial files (shapefiles)


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/directory"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |


- Web Feature Service


  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "name": "nyc",
        "connectionParameters": {
          "entry": [
            {"@key":"GET_CAPABILITIES_URL","$":"http://localhost:8080/geoserver/wfs?request=GetCapabilities"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |
  | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |
  | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |
  | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |
  | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |
  | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |
  | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |
  | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |
  | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |
  | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |
  | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |
  | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |
  | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |
  | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |
  | Maximum features | Positive integer used as a hard limit for the amount of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |
  | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |
  | WFS Strategy | Override wfs stragegy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |
  | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |
  | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |
  | Outputformat | This allows the user to specify an outputFormat, different from the default one. | advanced | String | False | ` ` |
 (required)
        :param str workspace_name: The name of the worskpace containing the data stores. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['body', 'workspace_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method create_datastore" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'body' is set
        if ('body' not in params or
                params['body'] is None):
            raise ValueError("Missing the required parameter `body` when calling `create_datastore`")  # noqa: E501
        # verify the required parameter 'workspace_name' is set
        if ('workspace_name' not in params or
                params['workspace_name'] is None):
            raise ValueError("Missing the required parameter `workspace_name` when calling `create_datastore`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['basicAuth']  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'POST',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def delete_datastore(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Delete data store  # noqa: E501

        Deletes a data store from the server.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_datastore(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool recurse: The recurse controls recursive deletion. When set to true all resources contained in the store are also removed. The default value is \"false\".
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.delete_datastore_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.delete_datastore_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def delete_datastore_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Delete data store  # noqa: E501

        Deletes a data store from the server.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.delete_datastore_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool recurse: The recurse controls recursive deletion. When set to true all resources contained in the store are also removed. The default value is \"false\".
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'recurse']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method delete_datastore" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if ('workspace_name' not in params or
                params['workspace_name'] is None):
            raise ValueError("Missing the required parameter `workspace_name` when calling `delete_datastore`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if ('store_name' not in params or
                params['store_name'] is None):
            raise ValueError("Missing the required parameter `store_name` when calling `delete_datastore`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []
        if 'recurse' in params:
            query_params.append(('recurse', params['recurse']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # Authentication setting
        auth_settings = ['basicAuth']  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'DELETE',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def get_data_store(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Retrieve a particular data store from a workspace  # noqa: E501

        Controls a particular data store in a given workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool quiet_on_not_found:
        :return: DataStoreWrapper
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.get_data_store_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.get_data_store_with_http_info(workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def get_data_store_with_http_info(self, workspace_name, store_name, **kwargs):  # noqa: E501
        """Retrieve a particular data store from a workspace  # noqa: E501

        Controls a particular data store in a given workspace.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_data_store_with_http_info(workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :param bool quiet_on_not_found:
        :return: DataStoreWrapper
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name', 'store_name', 'quiet_on_not_found']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_data_store" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if ('workspace_name' not in params or
                params['workspace_name'] is None):
            raise ValueError("Missing the required parameter `workspace_name` when calling `get_data_store`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if ('store_name' not in params or
                params['store_name'] is None):
            raise ValueError("Missing the required parameter `store_name` when calling `get_data_store`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []
        if 'quiet_on_not_found' in params:
            query_params.append(('quietOnNotFound', params['quiet_on_not_found']))  # noqa: E501

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['basicAuth']  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='DataStoreWrapper',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def get_datastores(self, workspace_name, **kwargs):  # noqa: E501
        """Get a list of data stores  # noqa: E501

        List all data stores in workspace ws.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_datastores(workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data stores. (required)
        :return: DataStoresListResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.get_datastores_with_http_info(workspace_name, **kwargs)  # noqa: E501
        else:
            (data) = self.get_datastores_with_http_info(workspace_name, **kwargs)  # noqa: E501
            return data

    def get_datastores_with_http_info(self, workspace_name, **kwargs):  # noqa: E501
        """Get a list of data stores  # noqa: E501

        List all data stores in workspace ws.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.get_datastores_with_http_info(workspace_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param str workspace_name: The name of the worskpace containing the data stores. (required)
        :return: DataStoresListResponse
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['workspace_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method get_datastores" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'workspace_name' is set
        if ('workspace_name' not in params or
                params['workspace_name'] is None):
            raise ValueError("Missing the required parameter `workspace_name` when calling `get_datastores`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        # HTTP header `Accept`
        header_params['Accept'] = self.api_client.select_header_accept(
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['basicAuth']  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores', 'GET',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type='DataStoresListResponse',  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)

    def modify_data_store(self, body, workspace_name, store_name, **kwargs):  # noqa: E501
        """Modify a data store.  # noqa: E501

        Modify data store ds.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.modify_data_store(body, workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param DataStoreInfoWrapper body: The updated data store definition.
For a PUT, only values which should be changed need to be included. The connectionParameters map counts as a single value, 
so if you change it all preexisting connection parameters will be overwritten.

The contents of the connection parameters will differ depending on the type of data store being added.

- GeoPackage

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"database","$":"file:///path/to/nyc.gpkg"},
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | database | Database | user | File | True | ` ` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | dbtype | Type | program | String | True | `geopkg` |
  | passwd | password used to login | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | user | user name to login as | user | String | False | ` ` |

- PostGIS

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"host","$":"localhost"},
            {"@key":"port","$":"5432"},
            {"@key":"database","$":"nyc"},
            {"@key":"user","$":"bob"},
            {"@key":"passwd","$":"postgres"},
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | port | Port | user | Integer | True | `5432` |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |
  | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |
  | create database params | Extra specifications appeneded to the CREATE DATABASE command | advanced | String | False | `` |
  | dbtype | Type | program | String | True | `postgis` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | passwd | password used to login | user | String | False | ` ` |
  | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows to push more of the filter into the database, increasing performance.the postgis table. | advanced | Boolean | False | `False` |
  | host | Host | user | String | True | `localhost` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |
  | database | Database | user | String | False | ` ` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | preparedStatements | Use prepared statements | user | Boolean | False | `False` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | schema | Schema | user | String | False | `public` |
  | user | user name to login as | user | String | True | ` ` |

- Shapefile

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/nyc.shp"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |

- Directory of spatial files (shapefiles)

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/directory"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |


- Web Feature Service

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"GET_CAPABILITIES_URL","$":"http://localhost:8080/geoserver/wfs?request=GetCapabilities"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |
  | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |
  | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |
  | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |
  | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |
  | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |
  | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |
  | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |
  | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |
  | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |
  | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |
  | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |
  | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |
  | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |
  | Maximum features | Positive integer used as a hard limit for the amount of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |
  | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |
  | WFS Strategy | Override wfs stragegy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |
  | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |
  | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |
  | Outputformat | This allows the user to specify an outputFormat, different from the default one. | advanced | String | False | ` ` |
 (required)
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """
        kwargs['_return_http_data_only'] = True
        if kwargs.get('async_req'):
            return self.modify_data_store_with_http_info(body, workspace_name, store_name, **kwargs)  # noqa: E501
        else:
            (data) = self.modify_data_store_with_http_info(body, workspace_name, store_name, **kwargs)  # noqa: E501
            return data

    def modify_data_store_with_http_info(self, body, workspace_name, store_name, **kwargs):  # noqa: E501
        """Modify a data store.  # noqa: E501

        Modify data store ds.  # noqa: E501
        This method makes a synchronous HTTP request by default. To make an
        asynchronous HTTP request, please pass async_req=True
        >>> thread = api.modify_data_store_with_http_info(body, workspace_name, store_name, async_req=True)
        >>> result = thread.get()

        :param async_req bool
        :param DataStoreInfoWrapper body: The updated data store definition.
For a PUT, only values which should be changed need to be included. The connectionParameters map counts as a single value, 
so if you change it all preexisting connection parameters will be overwritten.

The contents of the connection parameters will differ depending on the type of data store being added.

- GeoPackage

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"database","$":"file:///path/to/nyc.gpkg"},
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | database | Database | user | File | True | ` ` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | dbtype | Type | program | String | True | `geopkg` |
  | passwd | password used to login | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | user | user name to login as | user | String | False | ` ` |

- PostGIS

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"host","$":"localhost"},
            {"@key":"port","$":"5432"},
            {"@key":"database","$":"nyc"},
            {"@key":"user","$":"bob"},
            {"@key":"passwd","$":"postgres"},
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Connection timeout | number of seconds the connection pool will wait before timing out attempting to get a new connection (default, 20 seconds) | user | Integer | False | `20` |
  | validate connections | check connection is alive before using it | user | Boolean | False | `True` |
  | port | Port | user | Integer | True | `5432` |
  | Primary key metadata table | The optional table containing primary key structure and sequence associations. Can be expressed as 'schema.name' or just 'name' | user | String | False | ` ` |
  | Support on the fly geometry simplification | When enabled, operations such as map rendering will pass a hint that will enable the usage of ST_Simplify | user | Boolean | False | `True` |
  | create database | Creates the database if it does not exist yet | advanced | Boolean | False | `False` |
  | create database params | Extra specifications appeneded to the CREATE DATABASE command | advanced | String | False | `` |
  | dbtype | Type | program | String | True | `postgis` |
  | Batch insert size | Number of records inserted in the same batch (default, 1). For optimal performance, set to 100. | user | Integer | False | `1` |
  | namespace | Namespace prefix | user | String | False | ` ` |
  | Max connection idle time | number of seconds a connection needs to stay idle for the evictor to consider closing it | user | Integer | False | `300` |
  | Session startup SQL | SQL statement executed when the connection is grabbed from the pool | user | String | False | ` ` |
  | Expose primary keys | Expose primary key columns as attributes of the feature type | user | Boolean | False | `False` |
  | min connections | minimum number of pooled connection | user | Integer | False | `1` |
  | Max open prepared statements | Maximum number of prepared statements kept open and cached for each connection in the pool. Set to 0 to have unbounded caching, to -1 to disable caching | user | Integer | False | `50` |
  | Callback factory | Name of JDBCReaderCallbackFactory to enable on the data store | user | String | False | ` ` |
  | passwd | password used to login | user | String | False | ` ` |
  | encode functions | set to true to have a set of filter functions be translated directly in SQL. Due to differences in the type systems the result might not be the same as evaluating them in memory, including the SQL failing with errors while the in memory version works fine. However this allows to push more of the filter into the database, increasing performance.the postgis table. | advanced | Boolean | False | `False` |
  | host | Host | user | String | True | `localhost` |
  | Evictor tests per run | number of connections checked by the idle connection evictor for each of its runs (defaults to 3) | user | Integer | False | `3` |
  | Loose bbox | Perform only primary filter on bbox | user | Boolean | False | `True` |
  | Evictor run periodicity | number of seconds between idle object evitor runs (default, 300 seconds) | user | Integer | False | `300` |
  | Estimated extends | Use the spatial index information to quickly get an estimate of the data bounds | user | Boolean | False | `True` |
  | database | Database | user | String | False | ` ` |
  | fetch size | number of records read with each iteraction with the dbms | user | Integer | False | `1000` |
  | Test while idle | Periodically test the connections are still valid also while idle in the pool | user | Boolean | False | `True` |
  | max connections | maximum number of open connections | user | Integer | False | `10` |
  | preparedStatements | Use prepared statements | user | Boolean | False | `False` |
  | Session close-up SQL | SQL statement executed when the connection is released to the pool | user | String | False | ` ` |
  | schema | Schema | user | String | False | `public` |
  | user | user name to login as | user | String | True | ` ` |

- Shapefile

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/nyc.shp"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |

- Directory of spatial files (shapefiles)

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"url","$":"file:/path/to/directory"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | cache and reuse memory maps | only memory map a file one, then cache and reuse the map | advanced | Boolean | False | `True` |
  | namespace | uri to a the namespace | advanced | URI | False | ` ` |
  | filetype | Discriminator for directory stores | program | String | False | `shapefile` |
  | charset | character used to decode strings from the DBF file | advanced | Charset | False | `ISO-8859-1` |
  | create spatial index | enable/disable the automatic creation of spatial index | advanced | Boolean | False | `True` |
  | fstype | Enable using a setting of 'shape'. | advanced | String | False | `shape` |
  | url | url to a .shp file | user | URL | True | ` ` |
  | enable spatial index | enable/disable the use of spatial index for local shapefiles | advanced | Boolean | False | `True` |
  | memory mapped buffer | enable/disable the use of memory-mapped io | advanced | Boolean | False | `False` |
  | timezone | time zone used to read dates from the DBF file | advanced | TimeZone | False | `Pacific Standard Time` |


- Web Feature Service

  Examples:
  - application/json:

    ```
    {
      "dataStore": {
        "description": "A data store",
        "enabled": "true",
        "_default": "true",
        "connectionParameters": {
          "entry": [
            {"@key":"GET_CAPABILITIES_URL","$":"http://localhost:8080/geoserver/wfs?request=GetCapabilities"}
          ]
        }
      }
    }
    ```

  Connection Parameters:

  | key | description | level | type | required | default |
  | --- | ----------- | ----- | ---- | -------- | ------- |
  | Protocol | Sets a preference for the HTTP protocol to use when requesting WFS functionality. Set this value to Boolean.TRUE for POST, Boolean.FALSE for GET or NULL for AUTO | user | Boolean | False | ` ` |
  | WFS GetCapabilities URL | Represents a URL to the getCapabilities document or a server instance. | user | URL | False | ` ` |
  | Buffer Size | This allows the user to specify a buffer size in features. This param has a default value of 10 features. | user | Integer | False | `10` |
  | Filter compliance | Level of compliance to WFS specification (0-low,1-medium,2-high) | user | Integer | False | ` ` |
  | EntityResolver | Sets the entity resolver used to expand XML entities | program | EntityResolver | False | `org.geotools.xml.PreventLocalEntityResolver@75e98519` |
  | Time-out | This allows the user to specify a timeout in milliseconds. This param has a default value of 3000ms. | user | Integer | False | `3000` |
  | GmlComplianceLevel | Optional OGC GML compliance level required. | user | Integer | False | `0` |
  | Lenient | Indicates that datastore should do its best to create features from the provided data even if it does not accurately match the schema.  Errors will be logged but the parsing will continue if this is true.  Default is false | user | Boolean | False | `False` |
  | Password | This allows the user to specify a username. This param should not be used without the USERNAME param. | user | String | False | ` ` |
  | Use Default SRS | Use always the declared DefaultSRS for requests and reproject locally if necessary | advanced | Boolean | False | `False` |
  | Namespace | Override the original WFS type name namespaces | advanced | String | False | ` ` |
  | Username | This allows the user to specify a username. This param should not be used without the PASSWORD param. | user | String | False | ` ` |
  | Axis Order Filter | Indicates axis order used by the remote WFS server for filters. It applies only to WFS 1.x.0 servers. Default is the same as AXIS_ORDER | advanced | String | False | ` ` |
  | GmlCompatibleTypeNames | Use Gml Compatible TypeNames (replace : by _). | user | Boolean | False | `False` |
  | Maximum features | Positive integer used as a hard limit for the amount of Features to retrieve for each FeatureType. A value of zero or not providing this parameter means no limit. | user | Integer | False | `0` |
  | Axis Order | Indicates axis order used by the remote WFS server in result coordinates. It applies only to WFS 1.x.0 servers. Default is Compliant | advanced | String | False | `Compliant` |
  | WFS Strategy | Override wfs stragegy with either cubwerx, ionic, mapserver, geoserver, strict, nonstrict or arcgis strategy. | user | String | False | `auto` |
  | Try GZIP | Indicates that datastore should use gzip to transfer data if the server supports it. Default is true | user | Boolean | False | `True` |
  | Encoding | This allows the user to specify the character encoding of the XML-Requests sent to the Server. Defaults to UTF-8 | user | String | False | `UTF-8` |
  | Outputformat | This allows the user to specify an outputFormat, different from the default one. | advanced | String | False | ` ` |
 (required)
        :param str workspace_name: The name of the worskpace containing the data store. (required)
        :param str store_name: The name of the data store to retrieve. (required)
        :return: None
                 If the method is called asynchronously,
                 returns the request thread.
        """

        all_params = ['body', 'workspace_name', 'store_name']  # noqa: E501
        all_params.append('async_req')
        all_params.append('_return_http_data_only')
        all_params.append('_preload_content')
        all_params.append('_request_timeout')

        params = locals()
        for key, val in six.iteritems(params['kwargs']):
            if key not in all_params:
                raise TypeError(
                    "Got an unexpected keyword argument '%s'"
                    " to method modify_data_store" % key
                )
            params[key] = val
        del params['kwargs']
        # verify the required parameter 'body' is set
        if ('body' not in params or
                params['body'] is None):
            raise ValueError("Missing the required parameter `body` when calling `modify_data_store`")  # noqa: E501
        # verify the required parameter 'workspace_name' is set
        if ('workspace_name' not in params or
                params['workspace_name'] is None):
            raise ValueError("Missing the required parameter `workspace_name` when calling `modify_data_store`")  # noqa: E501
        # verify the required parameter 'store_name' is set
        if ('store_name' not in params or
                params['store_name'] is None):
            raise ValueError("Missing the required parameter `store_name` when calling `modify_data_store`")  # noqa: E501

        collection_formats = {}

        path_params = {}
        if 'workspace_name' in params:
            path_params['workspaceName'] = params['workspace_name']  # noqa: E501
        if 'store_name' in params:
            path_params['storeName'] = params['store_name']  # noqa: E501

        query_params = []

        header_params = {}

        form_params = []
        local_var_files = {}

        body_params = None
        if 'body' in params:
            body_params = params['body']
        # HTTP header `Content-Type`
        header_params['Content-Type'] = self.api_client.select_header_content_type(  # noqa: E501
            ['application/json'])  # noqa: E501

        # Authentication setting
        auth_settings = ['basicAuth']  # noqa: E501

        return self.api_client.call_api(
            '/workspaces/{workspaceName}/datastores/{storeName}', 'PUT',
            path_params,
            query_params,
            header_params,
            body=body_params,
            post_params=form_params,
            files=local_var_files,
            response_type=None,  # noqa: E501
            auth_settings=auth_settings,
            async_req=params.get('async_req'),
            _return_http_data_only=params.get('_return_http_data_only'),
            _preload_content=params.get('_preload_content', True),
            _request_timeout=params.get('_request_timeout'),
            collection_formats=collection_formats)
